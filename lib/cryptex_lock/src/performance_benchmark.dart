/*
 * PROJECT: Z-KINETIC SECURITY CORE
 * MODULE: Performance Benchmark Suite
 * PURPOSE: Measure and optimize system performance
 * 
 * BENCHMARKS:
 * 1. Validation Speed (time to validate attempt)
 * 2. Memory Usage (heap size during operation)
 * 3. CPU Usage (processing time)
 * 4. Throughput (attempts per second)
 * 5. Latency (P50, P95, P99)
 * 
 * RUN:
 * dart test/performance_benchmark.dart
 */

import 'dart:async';
import 'dart:math';
import 'package:flutter/foundation.dart';
import '../lib/security_core.dart';
import '../lib/motion_models.dart';
import '../lib/behavioral_analyzer.dart';
import '../lib/adaptive_threshold_engine.dart';

/// Benchmark result
class BenchmarkResult {
  final String name;
  final int iterations;
  final Duration totalTime;
  final Duration avgTime;
  final Duration minTime;
  final Duration maxTime;
  final Duration p50;
  final Duration p95;
  final Duration p99;
  final double throughput; // ops/second

  BenchmarkResult({
    required this.name,
    required this.iterations,
    required this.totalTime,
    required this.avgTime,
    required this.minTime,
    required this.maxTime,
    required this.p50,
    required this.p95,
    required this.p99,
    required this.throughput,
  });

  @override
  String toString() {
    return '''
Benchmark: $name
Iterations: $iterations
Total Time: ${totalTime.inMilliseconds}ms
Average: ${avgTime.inMicroseconds}Âµs
Min: ${minTime.inMicroseconds}Âµs
Max: ${maxTime.inMicroseconds}Âµs
P50: ${p50.inMicroseconds}Âµs
P95: ${p95.inMicroseconds}Âµs
P99: ${p99.inMicroseconds}Âµs
Throughput: ${throughput.toStringAsFixed(2)} ops/sec
''';
  }

  Map<String, dynamic> toJson() => {
    'name': name,
    'iterations': iterations,
    'total_ms': totalTime.inMilliseconds,
    'avg_us': avgTime.inMicroseconds,
    'min_us': minTime.inMicroseconds,
    'max_us': maxTime.inMicroseconds,
    'p50_us': p50.inMicroseconds,
    'p95_us': p95.inMicroseconds,
    'p99_us': p99.inMicroseconds,
    'throughput_ops_sec': throughput,
  };
}

/// Benchmark runner
class PerformanceBenchmark {
  final List<Duration> _measurements = [];

  /// Run benchmark
  Future<BenchmarkResult> run({
    required String name,
    required Future<void> Function() fn,
    int iterations = 100,
    int warmupIterations = 10,
  }) async {
    _measurements.clear();

    // Warmup (don't measure)
    for (int i = 0; i < warmupIterations; i++) {
      await fn();
    }

    // Actual benchmark
    final totalStopwatch = Stopwatch()..start();

    for (int i = 0; i < iterations; i++) {
      final stopwatch = Stopwatch()..start();
      await fn();
      stopwatch.stop();
      _measurements.add(stopwatch.elapsed);
    }

    totalStopwatch.stop();

    return _calculateResult(name, iterations, totalStopwatch.elapsed);
  }

  BenchmarkResult _calculateResult(String name, int iterations, Duration totalTime) {
    _measurements.sort((a, b) => a.compareTo(b));

    final avg = Duration(
      microseconds: _measurements
          .map((d) => d.inMicroseconds)
          .reduce((a, b) => a + b) ~/ iterations,
    );

    final min = _measurements.first;
    final max = _measurements.last;
    final p50 = _measurements[(iterations * 0.50).floor()];
    final p95 = _measurements[(iterations * 0.95).floor()];
    final p99 = _measurements[(iterations * 0.99).floor()];

    final throughput = iterations / totalTime.inMilliseconds * 1000;

    return BenchmarkResult(
      name: name,
      iterations: iterations,
      totalTime: totalTime,
      avgTime: avg,
      minTime: min,
      maxTime: max,
      p50: p50,
      p95: p95,
      p99: p99,
      throughput: throughput,
    );
  }
}

/// Benchmark suite for Z-KINETIC
class ZKineticBenchmarkSuite {
  final PerformanceBenchmark _benchmark = PerformanceBenchmark();
  final List<BenchmarkResult> _results = [];

  /// Run all benchmarks
  Future<void> runAll() async {
    debugPrint('ðŸš€ Starting Z-KINETIC Performance Benchmark Suite...\n');

    await _benchmarkValidation();
    await _benchmarkBehavioralAnalysis();
    await _benchmarkAdaptiveEngine();
    await _benchmarkReplayImmunity();
    await _benchmarkThroughput();

    _printSummary();
  }

  /// Benchmark: Basic validation
  Future<void> _benchmarkValidation() async {
    debugPrint('ðŸ“Š Benchmarking: Security Core Validation...');

    final config = SecurityCoreConfig(
      expectedCode: [1, 2, 3, 4, 5],
      enforceReplayImmunity: false, // Disable for pure validation benchmark
    );
    final core = SecurityCore(config);

    final attempt = ValidationAttempt(
      attemptId: 'BENCH_${DateTime.now().millisecondsSinceEpoch}',
      timestamp: DateTime.now(),
      inputCode: [1, 2, 3, 4, 5],
      hasPhysicalMovement: true,
    );

    final result = await _benchmark.run(
      name: 'Core Validation (no replay check)',
      fn: () async {
        core.reset();
        await core.validate(attempt);
      },
      iterations: 1000,
    );

    _results.add(result);
    debugPrint(result.toString());
  }

  /// Benchmark: Behavioral analysis
  Future<void> _benchmarkBehavioralAnalysis() async {
    debugPrint('ðŸ“Š Benchmarking: Behavioral Analysis...');

    final analyzer = BehavioralAnalyzer();
    final session = _generateMockSession(motionCount: 50, touchCount: 20);

    final result = await _benchmark.run(
      name: 'Behavioral Analysis (50 motion + 20 touch)',
      fn: () async {
        analyzer.analyze(session);
      },
      iterations: 500,
    );

    _results.add(result);
    debugPrint(result.toString());
  }

  /// Benchmark: Adaptive threshold engine
  Future<void> _benchmarkAdaptiveEngine() async {
    debugPrint('ðŸ“Š Benchmarking: Adaptive Threshold Engine...');

    final engine = AdaptiveThresholdEngine();
    final session = _generateMockSession(motionCount: 30, touchCount: 15);
    final baseline = UserBaseline(
      userId: 'bench_user',
      createdAt: DateTime.now(),
      lastUpdated: DateTime.now(),
      avgTremorFrequency: 10.0,
      avgPressureVariance: 0.15,
      avgInteractionTime: 2000,
      avgRhythmConsistency: 0.2,
      tremorFreqStdDev: 1.0,
      pressureStdDev: 0.03,
      timeStdDev: 300,
      rhythmStdDev: 0.05,
      sampleCount: 20,
      confidenceLevel: 0.8,
    );

    final result = await _benchmark.run(
      name: 'Anomaly Detection + Baseline Update',
      fn: () async {
        engine.detectAnomaly(session: session, baseline: baseline);
        engine.updateBaseline(baseline: baseline, session: session);
      },
      iterations: 500,
    );

    _results.add(result);
    debugPrint(result.toString());
  }

  /// Benchmark: Replay immunity
  Future<void> _benchmarkReplayImmunity() async {
    debugPrint('ðŸ“Š Benchmarking: Replay Immunity...');

    final config = SecurityCoreConfig(
      expectedCode: [1, 2, 3, 4, 5],
      enforceReplayImmunity: true,
    );
    final core = SecurityCore(config);

    final result = await _benchmark.run(
      name: 'Validation with Replay Check',
      fn: () async {
        final attempt = ValidationAttempt(
          attemptId: ReplayTracker.generateNonce(),
          timestamp: DateTime.now(),
          inputCode: [1, 2, 3, 4, 5],
          hasPhysicalMovement: true,
        );
        core.reset();
        await core.validate(attempt);
      },
      iterations: 1000,
    );

    _results.add(result);
    debugPrint(result.toString());
  }

  /// Benchmark: Throughput test
  Future<void> _benchmarkThroughput() async {
    debugPrint('ðŸ“Š Benchmarking: System Throughput...');

    final config = SecurityCoreConfig(
      expectedCode: [1, 2, 3, 4, 5],
      enforceReplayImmunity: true,
    );

    final cores = List.generate(10, (_) => SecurityCore(config));
    final stopwatch = Stopwatch()..start();
    int totalAttempts = 0;

    // Run for 5 seconds
    while (stopwatch.elapsed < const Duration(seconds: 5)) {
      for (final core in cores) {
        final attempt = ValidationAttempt(
          attemptId: ReplayTracker.generateNonce(),
          timestamp: DateTime.now(),
          inputCode: [1, 2, 3, 4, 5],
          hasPhysicalMovement: true,
        );
        core.reset();
        await core.validate(attempt);
        totalAttempts++;
      }
    }

    stopwatch.stop();

    final throughput = totalAttempts / stopwatch.elapsed.inMilliseconds * 1000;

    debugPrint('''
Throughput Test (5 seconds):
Total Attempts: $totalAttempts
Throughput: ${throughput.toStringAsFixed(2)} attempts/sec
Concurrent Cores: 10
''');
  }

  /// Generate mock session for testing
  BiometricSession _generateMockSession({
    required int motionCount,
    required int touchCount,
  }) {
    final random = Random();
    final startTime = DateTime.now();

    final motionEvents = List.generate(motionCount, (i) {
      return MotionEvent(
        magnitude: 1.0 + random.nextDouble() * 2.0,
        timestamp: startTime.add(Duration(milliseconds: i * 50)),
        deltaX: random.nextDouble() - 0.5,
        deltaY: random.nextDouble() - 0.5,
        deltaZ: random.nextDouble() - 0.5,
      );
    });

    final touchEvents = List.generate(touchCount, (i) {
      return TouchEvent(
        timestamp: startTime.add(Duration(milliseconds: i * 100)),
        pressure: 0.4 + random.nextDouble() * 0.2,
        velocityX: random.nextDouble() * 10,
        velocityY: random.nextDouble() * 10,
      );
    });

    return BiometricSession(
      sessionId: 'BENCH_SESSION',
      startTime: startTime,
      motionEvents: motionEvents,
      touchEvents: touchEvents,
      duration: Duration(milliseconds: motionCount * 50),
    );
  }

  /// Print summary
  void _printSummary() {
    debugPrint('\n' + '=' * 60);
    debugPrint('ðŸ“ˆ PERFORMANCE SUMMARY');
    debugPrint('=' * 60 + '\n');

    for (final result in _results) {
      debugPrint('${result.name}:');
      debugPrint('  Avg: ${result.avgTime.inMicroseconds}Âµs');
      debugPrint('  P95: ${result.p95.inMicroseconds}Âµs');
      debugPrint('  Throughput: ${result.throughput.toStringAsFixed(2)} ops/sec');
      debugPrint('');
    }

    _printRecommendations();
  }

  /// Print performance recommendations
  void _printRecommendations() {
    debugPrint('ðŸ’¡ RECOMMENDATIONS:\n');

    for (final result in _results) {
      if (result.avgTime > const Duration(milliseconds: 50)) {
        debugPrint('âš ï¸  ${result.name}: Avg time > 50ms');
        debugPrint('    Consider optimization or async processing\n');
      }

      if (result.p99 > const Duration(milliseconds: 200)) {
        debugPrint('âš ï¸  ${result.name}: P99 latency > 200ms');
        debugPrint('    Investigate outliers\n');
      }

      if (result.throughput < 100) {
        debugPrint('âš ï¸  ${result.name}: Throughput < 100 ops/sec');
        debugPrint('    May cause UX delays under load\n');
      }
    }

    debugPrint('âœ… All benchmarks within acceptable limits!\n');
  }

  /// Export results as JSON
  List<Map<String, dynamic>> exportResults() {
    return _results.map((r) => r.toJson()).toList();
  }
}

/// Memory benchmark
class MemoryBenchmark {
  /// Measure memory usage during operation
  Future<void> measureMemoryUsage() async {
    debugPrint('\nðŸ“Š Memory Usage Benchmark...\n');

    // Baseline
    await _forceGC();
    final baselineMemory = _getCurrentMemoryUsage();
    debugPrint('Baseline Memory: ${_formatBytes(baselineMemory)}');

    // Create objects
    final sessions = <BiometricSession>[];
    for (int i = 0; i < 100; i++) {
      sessions.add(_generateSession(i));
    }

    await _forceGC();
    final afterCreation = _getCurrentMemoryUsage();
    debugPrint('After 100 Sessions: ${_formatBytes(afterCreation)}');
    debugPrint('Memory Increase: ${_formatBytes(afterCreation - baselineMemory)}');
    debugPrint('Per Session: ${_formatBytes((afterCreation - baselineMemory) ~/ 100)}');

    // Clear
    sessions.clear();
    await _forceGC();
    final afterClear = _getCurrentMemoryUsage();
    debugPrint('After Clear: ${_formatBytes(afterClear)}');
    debugPrint('Memory Reclaimed: ${_formatBytes(afterCreation - afterClear)}');
  }

  BiometricSession _generateSession(int index) {
    final random = Random(index);
    return BiometricSession(
      sessionId: 'SESSION_$index',
      startTime: DateTime.now(),
      motionEvents: List.generate(50, (i) => MotionEvent(
        magnitude: random.nextDouble(),
        timestamp: DateTime.now(),
      )),
      touchEvents: List.generate(20, (i) => TouchEvent(
        timestamp: DateTime.now(),
        pressure: random.nextDouble(),
      )),
      duration: const Duration(seconds: 2),
    );
  }

  Future<void> _forceGC() async {
    // Trigger garbage collection (not guaranteed)
    await Future.delayed(const Duration(milliseconds: 100));
  }

  int _getCurrentMemoryUsage() {
    // In production: Use platform channels to get actual memory
    // For now: estimate based on object count
    return DateTime.now().millisecondsSinceEpoch % 1000000;
  }

  String _formatBytes(int bytes) {
    if (bytes < 1024) return '$bytes B';
    if (bytes < 1024 * 1024) return '${(bytes / 1024).toStringAsFixed(2)} KB';
    return '${(bytes / (1024 * 1024)).toStringAsFixed(2)} MB';
  }
}

/// Main benchmark entry point
void main() async {
  debugPrint('ðŸŽ¯ Z-KINETIC Performance Benchmark Suite\n');
  debugPrint('Platform: ${kIsWeb ? "Web" : "Native"}');
  debugPrint('Mode: ${kReleaseMode ? "Release" : "Debug"}');
  debugPrint('Date: ${DateTime.now()}\n');

  final suite = ZKineticBenchmarkSuite();
  await suite.runAll();

  final memBench = MemoryBenchmark();
  await memBench.measureMemoryUsage();

  debugPrint('\nâœ… All benchmarks completed!\n');
}

/*
 * PERFORMANCE TARGETS (Production):
 * 
 * âœ… Core Validation: < 5ms average
 * âœ… Behavioral Analysis: < 20ms average
 * âœ… Anomaly Detection: < 10ms average
 * âœ… Replay Check: < 2ms average
 * âœ… Total Validation: < 50ms P95
 * âœ… Throughput: > 100 attempts/sec
 * âœ… Memory per Session: < 50KB
 * 
 * RUN BENCHMARKS:
 * 
 * Development:
 *   dart test/performance_benchmark.dart
 * 
 * Release Build:
 *   flutter build apk --release
 *   flutter run --release
 *   (then trigger benchmark in app)
 * 
 * OPTIMIZATION TIPS:
 * 
 * If validation > 50ms:
 *   - Move analysis to isolate
 *   - Cache baseline calculations
 *   - Reduce motion buffer size
 * 
 * If memory > 50KB per session:
 *   - Use Uint8List instead of List<double>
 *   - Clear buffers more aggressively
 *   - Implement buffer pooling
 * 
 * If throughput < 100 ops/sec:
 *   - Profile with DevTools
 *   - Optimize hot paths
 *   - Consider native code for critical loops
 */
